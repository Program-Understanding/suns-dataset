Each subdirectory in the tools directory should contain a control flow analysis tool.
You can build all of these tools using the script "build_all_the_tools" or
"build_all_the_tools_with_a_proxy" if custom configuration is needed.  You can
also build each tool individually by entering each directory and the running
"build" or "build_with_proxy".  For now, "building" creates a docker container
that can run a tool.

Each directory (each tool) contains a file "questions.json" that defines what
questions the tool can answer, and what script is needed to have the tool answer
a question.  If custom scripts are always necessary for a tool to answer a
question, the "question.json" file will not contain any script properties.

Each cfr file (in the datasets) may have one or more corresponding -<tool>-cfrs.json file,
where the "cfrs" is a cfr file that specifies a "script" (s) designed to solve the specific
question.

Generally, tools prefer to have generic scripts...one does not need a special script for
each and every tool...however, sometimes you might.

The analysis checks to see if there are one or more "cfrs" file... and then it will simply run that for the
tool in question... and won't run the generic script...otherwise, it checks to see for each
tool if the tool is willing to answer the question, and then if so, uses a generic script
for that question.

If you have any local tools that don't run inside a docker container, you may need to
manually install the package in tools/cfr_helper if you are using it.